{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7e344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import pretty_midi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"pretty_midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df868d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total songs with all 3 formats: 50\n"
     ]
    }
   ],
   "source": [
    "#Loading the files\n",
    "\n",
    "DATA_DIR = \"Audio_Midi_Lyrics\"\n",
    "EMBEDDINGS_DIR = \"Embeddings\"\n",
    "file_ids = sorted(list(set(f.split('.')[0] for f in os.listdir(DATA_DIR))))\n",
    "print(f\"Total songs with all 3 formats: {len(file_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aba4fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and embedding audio with CLAP\n",
    "\n",
    "from transformers import ClapProcessor, ClapModel\n",
    "\n",
    "clap_processor = ClapProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "clap_model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "def get_audio_embedding(file_id):\n",
    "    from transformers import ClapProcessor, ClapModel\n",
    "\n",
    "    wav_path = os.path.join(DATA_DIR, f\"{file_id}.wav\")\n",
    "    audio, sr = torchaudio.load(wav_path)  # shape: [1, N]\n",
    "\n",
    "    # Ensure mono\n",
    "    if audio.shape[0] > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "\n",
    "    # Resample to 48kHz\n",
    "    if sr != 48000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=48000)\n",
    "        audio = resampler(audio)\n",
    "\n",
    "    # Convert to float32\n",
    "    audio = audio.squeeze().numpy().astype(np.float32)\n",
    "\n",
    "    # Pass as list\n",
    "    inputs = clap_processor(audios=[audio], sampling_rate=48000, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_emb = clap_model.get_audio_features(**inputs)\n",
    "\n",
    "    return audio_emb.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8062351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting MIDI Features\n",
    "def get_midi_features(file_id):\n",
    "    midi_path = os.path.join(DATA_DIR, f\"{file_id}.mid\")\n",
    "    midi = pretty_midi.PrettyMIDI(midi_path)\n",
    "    notes = [n.pitch for inst in midi.instruments for n in inst.notes if not inst.is_drum]\n",
    "    if not notes:\n",
    "        return np.zeros(3)\n",
    "    tempo = midi.get_tempo_changes()[1].mean() if midi.get_tempo_changes()[1].size > 0 else 120.0\n",
    "    note_density = len(notes) / midi.get_end_time()\n",
    "    avg_pitch = np.mean(notes)\n",
    "    return np.array([tempo, note_density, avg_pitch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1841bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding lyrics with BERT\n",
    "\n",
    "lyrics_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_lyrics_embedding(file_id):\n",
    "    txt_path = os.path.join(DATA_DIR, f\"{file_id}.txt\")\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return lyrics_model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29625215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all the vectors\n",
    "\n",
    "def get_full_embedding(file_id):\n",
    "    audio_emb = get_audio_embedding(file_id)\n",
    "    midi_emb = get_midi_features(file_id)\n",
    "    lyrics_emb = get_lyrics_embedding(file_id)\n",
    "    return np.concatenate([audio_emb, midi_emb, lyrics_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f5462d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved in Embeddings folder\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = []\n",
    "valid_ids = []\n",
    "\n",
    "for fid in file_ids:\n",
    "    try:\n",
    "        vec = get_full_embedding(fid)\n",
    "        all_embeddings.append(vec)\n",
    "        valid_ids.append(fid)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Skipping {fid}: {e}\")\n",
    "\n",
    "all_embeddings = np.stack(all_embeddings)\n",
    "np.save(\"Embeddings/embeddings_full.npy\", all_embeddings)    #Edit the text to use the assgined directory name...\n",
    "np.save(\"Embeddings/ids_full.npy\", valid_ids)                #Edit the text to use the assgined directory name...\n",
    "\n",
    "print(\"Embeddings saved in Embeddings folder\")    #Edit the text to use the assgined directory name..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01eef8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_embedding(text_query):\n",
    "    return lyrics_model.encode(text_query)  # same space as lyrics_emb\n",
    "\n",
    "def search(query_text, top_k=5):\n",
    "    print(f\"\\nüîç Query: {query_text}\")\n",
    "    q_vec = query_embedding(query_text)\n",
    "    \n",
    "    # Extend query to match full vector length (by padding or averaging)\n",
    "    q_extended = np.concatenate([\n",
    "        np.zeros(all_embeddings.shape[1] - q_vec.shape[0]),  # pad audio+midi dims\n",
    "        q_vec\n",
    "    ])\n",
    "    \n",
    "    sims = cosine_similarity(q_extended.reshape(1, -1), all_embeddings)[0]\n",
    "    top_indices = np.argsort(sims)[::-1][:top_k]\n",
    "    \n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"{i+1}. {valid_ids[idx]}.wav ‚Äî Similarity: {sims[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e3398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query: show me loops that feel like heartbreak in spring\n",
      "1. 522.wav ‚Äî Similarity: 0.0046\n",
      "2. 514.wav ‚Äî Similarity: 0.0033\n",
      "3. 069.wav ‚Äî Similarity: 0.0032\n",
      "4. 246.wav ‚Äî Similarity: 0.0032\n",
      "5. 447.wav ‚Äî Similarity: 0.0027\n"
     ]
    }
   ],
   "source": [
    "search(\"show me loops that feel like heartbreak in spring\")\n",
    "\n",
    "#Have to verify the authenticity of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680a7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca93232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1509d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
